# 🚀 Podcast Quality Fixes - Implementation Status

**Date:** October 16, 2025  
**Goal:** Fix podcast generation to use real research + 2-speaker format

---

## ✅ Completed

### 1. Added Research Pipeline Import
- ✅ Imported `ComprehensiveResearchPipeline` and `ResearchSource` from `research_pipeline.py`
- ✅ This enables real research from PubMed, arXiv, NASA ADS, News API, etc.

### 2. Added 2-Speaker Voice Configuration
- ✅ Created `COPERNICUS_VOICES` dict with Matilda (female) and Adam (male)
- ✅ Voice IDs match ElevenLabs exactly
- ✅ Added `get_speaker_labels()` function returning ["MATILDA", "ADAM"]

---

## 🔄 In Progress

### 3. Modifying Key Functions

Need to update these functions in `main.py`:

#### A. `generate_topic_research_content_vertex()` (Line ~882)
**Changes:**
- Update prompt to use MATILDA and ADAM only (not HOST/EXPERT/QUESTIONER)
- Add instruction to cite only real research
- Update structure for 2-speaker dialogue

#### B. `generate_topic_research_content()` (Line ~622)
**Changes:**
- Same as above but for Google AI API version

#### C. `run_podcast_generation_job()` (Line ~1507)
**Changes:**
- ADD: Research pipeline integration BEFORE content generation
- ADD: Research validation (minimum 3 sources)
- REMOVE: Fake fallback template (lines 1593-1650)
- ADD: Fail job if insufficient research

#### D. `generate_podcast_from_analysis_vertex()` (Line ~777)
**Changes:**
- Update to 2-speaker format for paper-based podcasts

#### E. `generate_podcast_from_analysis()` (Line ~479)
**Changes:**
- Update to 2-speaker format for paper-based podcasts

---

## 📋 Remaining Tasks

### Task 1: Create New Function `generate_content_from_research()`
**Purpose:** Generate podcast content from real research sources

```python
async def generate_content_from_research(request: PodcastRequest, research_sources: List[ResearchSource]) -> dict:
    """Generate 2-speaker podcast content from real research sources"""
    
    # Validate sufficient sources
    if len(research_sources) < 3:
        raise Exception(f"Insufficient research sources: {len(research_sources)}")
    
    # Build research context from real papers
    research_context = build_research_context(research_sources[:10])
    
    # Generate with proper 2-speaker prompt
    prompt = create_2_speaker_research_prompt(request, research_context)
    
    # Call LLM
    if vertex_ai_model:
        return await call_vertex_with_prompt(prompt)
    else:
        return await call_google_ai_with_prompt(prompt)
```

### Task 2: Update `run_podcast_generation_job()`
**Add research step at the beginning:**

```python
async def run_podcast_generation_job(job_id: str, request: PodcastRequest, subscriber_id: Optional[str] = None):
    # ... existing setup code ...
    
    # NEW: STEP 0 - PERFORM REAL RESEARCH
    print(f"🔍 Job {job_id}: Researching topic with multiple APIs")
    research_pipeline = ComprehensiveResearchPipeline()
    
    try:
        research_sources = await research_pipeline.comprehensive_search(
            subject=request.topic,
            additional_context=request.additional_instructions or "",
            source_links=request.source_links or [],
            depth="comprehensive",
            include_preprints=True,
            include_social_trends=True  # For topics like 3i/ATLAS
        )
        
        print(f"📚 Found {len(research_sources)} research sources")
        
        # Log source breakdown
        for source in research_sources[:5]:
            print(f"  - {source.source}: {source.title[:60]}...")
        
        # VALIDATE: Need at least 3 sources
        if len(research_sources) < 3:
            error_msg = f"Insufficient research for '{request.topic}': found {len(research_sources)} sources, need ≥3"
            print(f"❌ {error_msg}")
            job_ref.update({
                'status': 'failed',
                'error': error_msg,
                'error_type': 'insufficient_research',
                'updated_at': datetime.utcnow().isoformat()
            })
            return
        
        # Store research metadata in job
        job_ref.update({
            'research_sources_count': len(research_sources),
            'research_sources_summary': [
                {'title': s.title, 'source': s.source, 'doi': s.doi}
                for s in research_sources[:10]
            ]
        })
        
    except Exception as e:
        print(f"❌ Research failed: {e}")
        job_ref.update({
            'status': 'failed',
            'error': f"Research pipeline error: {str(e)}",
            'updated_at': datetime.utcnow().isoformat()
        })
        return
    
    # ... continue with content generation using research_sources ...
```

### Task 3: Remove Fake Fallback Template
**Delete lines ~1593-1650** that generate fake content:

```python
# DELETE THIS ENTIRE BLOCK:
if 'description' not in content or not content.get('description'):
    print("⚠️  No description generated by AI - creating fallback description")
    content['description'] = f"""## Episode Overview
This episode explores the fascinating world of {request.topic}...
## References
- Smith, J. et al. (2024). Recent advances...  # FAKE!
```

**Replace with:**
```python
# Validate that content was actually generated
if 'description' not in content or not content.get('description'):
    raise Exception("Content generation failed - no description produced")

if 'script' not in content or not content.get('script'):
    raise Exception("Content generation failed - no script produced")
```

### Task 4: Update All Prompts to 2-Speaker Format
**In every prompt template, replace:**
- `HOST:` → `MATILDA:`
- `EXPERT:` → `ADAM:`
- Remove `QUESTIONER:` entirely
- Update instructions to say "2 speakers: MATILDA and ADAM"

---

## 🧪 Testing Plan

After implementation:

### Test 1: 3i/ATLAS Comet
```bash
# Generate podcast
curl -X POST http://localhost:8080/generate-podcast-with-subscriber \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "3i/ATLAS comet",
    "category": "physics",
    "expertise_level": "intermediate",
    "duration": "5-10 minutes"
  }'
```

**Expected Results:**
- ✅ Finds papers from NASA ADS
- ✅ Finds news articles about the comet
- ✅ References real astronomers and observations
- ✅ Script uses only MATILDA: and ADAM: labels
- ✅ No fake DOIs (Smith et al., Johnson et al.)

### Test 2: Obscure Topic (Should Fail)
```bash
curl -X POST http://localhost:8080/generate-podcast-with-subscriber \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "Quantum Flibbertigibbet Dynamics",
    "category": "physics",
    "expertise_level": "advanced"
  }'
```

**Expected Results:**
- ❌ Job status: "failed"
- ❌ Error: "Insufficient research sources"
- ❌ No fake content generated

---

## 📊 Progress Summary

| Component | Status | Notes |
|-----------|--------|-------|
| Research Pipeline Import | ✅ Done | Line 16 |
| 2-Speaker Voice Config | ✅ Done | Lines 65-84 |
| Update Prompts | ⏳ In Progress | Multiple functions |
| Remove Fake Template | ⏳ Pending | Lines ~1593-1650 |
| Add Research Integration | ⏳ Pending | In `run_podcast_generation_job()` |
| Testing | ⏳ Pending | After deployment |

---

## ⚠️ Important Notes

1. **Don't Deploy Partial Changes** - Complete all updates before deploying
2. **Test Locally First** - Use `pytest` or manual curl tests
3. **Monitor First Podcasts** - Check quality of first few generated after deployment
4. **Have Rollback Plan** - Keep current `main.py` as `main_backup.py`

---

## 🎯 Next Steps for Developer

Since these are extensive changes across a 3000-line file, I recommend:

**Option A: Complete Implementation** (4-6 hours)
- Update all 5 functions mentioned above
- Add new `generate_content_from_research()` function
- Remove fake template
- Test locally
- Deploy to Cloud Run

**Option B: Staged Approach** (2-3 hours per stage)
- **Stage 1:** Just remove fake template + add validation (immediate quality improvement)
- **Stage 2:** Add research integration
- **Stage 3:** Update to 2-speaker format

**My Recommendation:** Option A - Do it all at once to avoid inconsistencies

---

## 💬 User Approval Required

Before proceeding with full implementation, user should confirm:
1. ✅ Approve 2-speaker format (Matilda + Adam)
2. ✅ Approve research pipeline integration
3. ✅ Approve "fail fast" approach (no fake content on research failure)
4. ⏳ Approve timeline (4-6 hours of focused work)

---

*Last Updated: October 16, 2025 - Ready to proceed with full implementation*

